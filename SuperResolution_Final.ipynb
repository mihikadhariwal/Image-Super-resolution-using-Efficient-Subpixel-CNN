{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtlHi0sm37v5"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "from keras.utils import load_img\n",
        "from keras.utils import array_to_img\n",
        "from keras.utils import img_to_array\n",
        "from keras.preprocessing import image_dataset_from_directory\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHw0PaMm8osP"
      },
      "outputs": [],
      "source": [
        "! gdown --id 1AacCu4C_rfOtm-LINJd-KByt_r_PhREi\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff8YgWiv854h"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/DIV2K_train_LR_bicubic_X2 (2).zip' -d '/content/extracted_data_train/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaMkPmEx8_Ze"
      },
      "outputs": [],
      "source": [
        "! gdown --id 1sHbd5Tm_wjFPwXHShoQLzS2RedJFd4_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR7fyHWP9Sad"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/DIV2K_test_LR_bicubic_x2.zip' -d '/content/extracted_data_test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF-mcE9O9YW6"
      },
      "outputs": [],
      "source": [
        "! gdown --id 1y2GbjCpxLe574r0BnEvDvlrTrnFOZ27E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE4xQE7o9ihG"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/DIV2K_valid_LR_bicubic_X2.zip' -d '/content/extracted_data_valid/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSg_gMVJrc5p"
      },
      "outputs": [],
      "source": [
        "SUPER_RES_MODEL = '/content/super_res_model'\n",
        "TRAINING_PLOT =  '/content/training_plot'\n",
        "VISUALIZATION_PATH = '/content/visualizations'\n",
        "\n",
        "\n",
        "os.makedirs(SUPER_RES_MODEL, exist_ok=True)\n",
        "os.makedirs(TRAINING_PLOT, exist_ok=True)\n",
        "os.makedirs(VISUALIZATION_PATH, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYcFCYiY9uSJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "ORIG_SIZE = (300, 300)\n",
        "DOWN_FACTOR = 6\n",
        "\n",
        "RDB_LAYERS = 3\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 20\n",
        "LR = 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BDqJwDY-0We"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "def process_input(imagePath, downFactor=DOWN_FACTOR):\n",
        "\n",
        "\tresizeShape = ORIG_SIZE[0] // downFactor\n",
        "\n",
        "\torigImage = tf.io.read_file(imagePath)\n",
        "\torigImage = tf.image.decode_png(origImage, 3)\n",
        "\torigImage = tf.image.convert_image_dtype(origImage, tf.float32)\n",
        "\torigImage = tf.image.resize(origImage, ORIG_SIZE,\n",
        "\t\tmethod=\"area\")\n",
        "\n",
        "\n",
        "\torigImageYUV = tf.image.rgb_to_yuv(origImage)\n",
        "\t(target, _, _) = tf.split(origImageYUV, 3, axis=-1)\n",
        "\n",
        "\tdownImage = tf.image.resize(target, [resizeShape, resizeShape],\n",
        "\t\tmethod=\"area\")\n",
        "\n",
        "\ttarget = tf.clip_by_value(target, 0.0, 1.0)\n",
        "\tdownImage = tf.clip_by_value(downImage, 0.0, 1.0)\n",
        "\n",
        "\treturn (downImage, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k5neCU8C96j"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "def rdb_block(inputs, numLayers):\n",
        "\n",
        "\tchannels = inputs.get_shape()[-1]\n",
        "\tstoredOutputs = [inputs]\n",
        "\n",
        "\tfor _ in range(numLayers):\n",
        "\n",
        "\t\tlocalConcat = tf.concat(storedOutputs, axis=-1)\n",
        "\t\tout = Conv2D(filters=channels, kernel_size=3, padding=\"same\",\n",
        "\t\t\tactivation=\"relu\",\n",
        "\t\t\tkernel_initializer=\"Orthogonal\")(localConcat)\n",
        "\t\tstoredOutputs.append(out)\n",
        "\n",
        "\tfinalConcat = tf.concat(storedOutputs, axis=-1)\n",
        "\tfinalOut = Conv2D(filters=inputs.get_shape()[-1], kernel_size=1,\n",
        "\t\tpadding=\"same\", activation=\"relu\",\n",
        "\t\tkernel_initializer=\"Orthogonal\")(finalConcat)\n",
        "\tfinalOut = Add()([finalOut, inputs])\n",
        "\n",
        "\treturn finalOut"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subpixel_net(downsampleFactor=DOWN_FACTOR, channels=1, rdbLayers=RDB_LAYERS):\n",
        "\n",
        "    inputs = Input((None, None, 1))\n",
        "\n",
        "    x = Conv2D(64, 5, padding=\"same\", strides=(1, 1), activation=\"relu\", kernel_initializer=\"Orthogonal\")(inputs)\n",
        "    x = Conv2D(64, 3, padding=\"same\", strides=(1, 1), activation=\"relu\", kernel_initializer=\"Orthogonal\")(x)\n",
        "\n",
        "\n",
        "\n",
        "    x = Conv2D(32, 3, padding=\"same\", activation=\"relu\", strides=(1, 1), kernel_initializer=\"Orthogonal\")(x)\n",
        "    x = Conv2D(32, 3, padding=\"same\", activation=\"relu\", strides=(1, 1), kernel_initializer=\"Orthogonal\")(x)\n",
        "\n",
        "\n",
        "    x = rdb_block(x, numLayers=rdbLayers)\n",
        "    x = Conv2D(32, 3, padding=\"same\", strides=(1, 1), activation=\"relu\", kernel_initializer=\"Orthogonal\")(x)\n",
        "    x = rdb_block(x, numLayers=rdbLayers)\n",
        "    x = Conv2D(16, 2, padding=\"same\", strides=(1, 1), activation=\"relu\", kernel_initializer=\"Orthogonal\")(x)\n",
        "    x = rdb_block(x, numLayers=rdbLayers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # x = Conv2D(256, 3, padding=\"same\", activation=\"relu\", strides=(1, 1), kernel_initializer=\"Orthogonal\")(x)\n",
        "\n",
        "    x = Conv2D(channels * (downsampleFactor ** 2), 3, padding=\"same\",\n",
        "               activation=\"sigmoid\", kernel_initializer=\"Orthogonal\")(x)\n",
        "\n",
        "    # x = Conv2D(36, kernel_size=3, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "    outputs = tf.nn.depth_to_space(x, downsampleFactor)\n",
        "\n",
        "\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "OKgJAl7XHw87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4D23MueIVIM"
      },
      "outputs": [],
      "source": [
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def psnr(orig, pred):\n",
        "\n",
        "\torig = orig * 255.0\n",
        "\torig = tf.cast(orig, tf.uint8)\n",
        "\torig = tf.clip_by_value(orig, 0, 255)\n",
        "\n",
        "\tpred = pred * 255.0\n",
        "\tpred = tf.cast(pred, tf.uint8)\n",
        "\tpred = tf.clip_by_value(pred, 0, 255)\n",
        "\n",
        "\treturn tf.image.psnr(orig, pred, max_val=255)\n",
        "\n",
        "\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "print(\"[INFO] loading images from disk...\")\n",
        "trainPaths = list(paths.list_images('/content/extracted_data_train'))\n",
        "valPaths = list(paths.list_images('/content/extracted_data_valid'))\n",
        "trainDS = tf.data.Dataset.from_tensor_slices(trainPaths)\n",
        "valDS = tf.data.Dataset.from_tensor_slices(valPaths)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrpUHPsmhhyS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "trainDS = trainDS.map(process_input,\n",
        "\t\t\t\t\t  num_parallel_calls=AUTO).batch(\n",
        "\tBATCH_SIZE).prefetch(AUTO)\n",
        "valDS = valDS.map(process_input,\n",
        "\t\t\t\t  num_parallel_calls=AUTO).batch(\n",
        "\tBATCH_SIZE).prefetch(AUTO)\n",
        "\n",
        "print(\"[INFO] initializing and training model...\")\n",
        "model = get_subpixel_net()\n",
        "model.summary()\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=psnr)\n",
        "H = model.fit(trainDS, validation_data=valDS, epochs=EPOCHS)\n",
        "\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(H.history[\"psnr\"], label=\"train_psnr\")\n",
        "plt.plot(H.history[\"val_psnr\"], label=\"val_psnr\")\n",
        "plt.title(\"Training Loss and PSNR\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/PSNR\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(TRAINING_PLOT)\n",
        "\n",
        "print(\"[INFO] serializing model...\")\n",
        "model.save(SUPER_RES_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9HdioTbkxK2"
      },
      "outputs": [],
      "source": [
        "def psnr(orig, pred):\n",
        "\n",
        "\torig = orig * 255.0\n",
        "\torig = tf.cast(orig, tf.uint8)\n",
        "\torig = tf.clip_by_value(orig, 0, 255)\n",
        "\n",
        "\tpred = pred * 255.0\n",
        "\tpred = tf.cast(pred, tf.uint8)\n",
        "\tpred = tf.clip_by_value(pred, 0, 255)\n",
        "\n",
        "\treturn tf.image.psnr(orig, pred, max_val=255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFcccuHjmhn6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_image(imagePath):\n",
        "\n",
        "\torig = load_img(imagePath)\n",
        "\tdownsampled = orig.resize((orig.size[0] // DOWN_FACTOR,\n",
        "\t\torig.size[1] // DOWN_FACTOR), Image.BICUBIC)\n",
        "\n",
        "\treturn (orig, downsampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo6R4yjHmv0S"
      },
      "outputs": [],
      "source": [
        "def get_y_channel(image):\n",
        "\n",
        "\tycbcr = image.convert(\"YCbCr\")\n",
        "\t(y, cb, cr) = ycbcr.split()\n",
        "\n",
        "\ty = np.array(y)\n",
        "\ty = y.astype(\"float32\") / 255.0\n",
        "\n",
        "\treturn (y, cb, cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9MdxFsWm6Sl"
      },
      "outputs": [],
      "source": [
        "def clip_numpy(image):\n",
        "\n",
        "\timage = tf.cast(image * 255.0, tf.uint8)\n",
        "\timage = tf.clip_by_value(image, 0, 255).numpy()\n",
        "\n",
        "\treturn image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3h2ShBKm90t"
      },
      "outputs": [],
      "source": [
        "def postprocess_image(y, cb, cr):\n",
        "\n",
        "\ty = clip_numpy(y).squeeze()\n",
        "\ty = y.reshape(y.shape[0], y.shape[1])\n",
        "\ty = Image.fromarray(y, mode=\"L\")\n",
        "\n",
        "\toutputCB= cb.resize(y.size, Image.BICUBIC)\n",
        "\toutputCR= cr.resize(y.size, Image.BICUBIC)\n",
        "\n",
        "\tfinal = Image.merge(\"YCbCr\", (y, outputCB, outputCR)).convert(\"RGB\")\n",
        "\treturn np.array(final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTLwwH9cnDLG"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "print(\"[INFO] loading test images...\")\n",
        "testPaths = list(paths.list_images('/content/extracted_data_test'))\n",
        "currentTestPaths = np.random.choice(testPaths, 10)\n",
        "# currentTestPaths = '/content/extracted_data_test/DIV2K_test_LR_bicubic_x2/0793x2.png'\n",
        "\n",
        "print(\"[INFO] loading model...\")\n",
        "superResModel = load_model(SUPER_RES_MODEL,\n",
        "\tcustom_objects={\"psnr\" : psnr})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv-Xs6f_8Cc0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "print(\"[INFO] performing predictions...\")\n",
        "for (i, path) in enumerate(currentTestPaths):\n",
        "\n",
        "    (orig, downsampled) = load_image(path)\n",
        "\n",
        "\n",
        "    (y, cb, cr) = get_y_channel(downsampled)\n",
        "    upscaledY = superResModel.predict(y[None, ...])[0]\n",
        "\n",
        "    finalOutput = postprocess_image(upscaledY, cb, cr)\n",
        "\n",
        "\n",
        "\n",
        "    path = os.path.join(VISUALIZATION_PATH, f\"{i}_viz.png\")\n",
        "    (fig, ((ax1, ax4, ax2))) = plt.subplots(nrows=1, ncols=3, figsize=(18, 18))\n",
        "\n",
        "    ax1.imshow(downsampled)\n",
        "    ax1.set_title(\"Preprocessed Downscaled Image\")\n",
        "\n",
        "    ax2.imshow(orig)\n",
        "    ax2.set_title(\"Original High-Res Image\")\n",
        "\n",
        "\n",
        "\n",
        "    ax4.imshow(finalOutput)\n",
        "    ax4.set_title(\"Super-res Model\")\n",
        "\n",
        "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}